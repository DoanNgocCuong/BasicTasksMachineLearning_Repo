{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1) Chuẩn bị dữ liệu\n",
    " Tải xuống bộ dữ liệu News Aggregator Data Set, tạo ra dữ liệu huấn luyện (train.txt), dữ liệu\n",
    " kiểm chứng (valid.txt) và dữ liệu đánh giá (test.txt) theo hướng dẫn dưới đây.\n",
    " 1. Giải nén file zip đã tải xuống, đọc hướng dẫn của file readme.txt\n",
    " 2. Trích xuất ra các example (bài báo) của các báo \"Reuters\", \"Huffington Post\",\n",
    " \"Businessweek\", \"Contactmusic.com\", \"Daily Mail\".\n",
    " 3. Sắp xếp lại các example đã trích xuất theo thứ tự ngẫu nhiên.\n",
    " 4. Phân chia các example đã trích xuất với tỉ lệ 80% cho tập train, còn lại dùng 10%\n",
    " cho tập kiểm chứng và 10% cho tập đánh giá và lưu thành các file train.txt, valid.txt,\n",
    " test.txt. Trong các file, mỗi dòng lưu một example, tên của `category` và `title` của các\n",
    " bài báo được phân cách bởi dấu tab. Các file này sau này sẽ được dùng lại trong\n",
    " các bài tập tiếp theo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link dataset: https://archive.ics.uci.edu/dataset/359/news+aggregator\n",
    "\n",
    "**Nội dung (CONTENT)**: \n",
    "   - **FILENAME #1**: `newsCorpora.csv` chứa thông tin về các trang tin tức với các trường như ID, tiêu đề, URL, nhà xuất bản, loại tin tức, câu chuyện, tên miền và thời gian xuất bản.\n",
    "   FORMAT: `ID \t TITLE \t URL \t PUBLISHER \t CATEGORY \t STORY \t HOSTNAME \t TIMESTAMP`\n",
    "\n",
    "   - **FILENAME #2**: `2pageSessions.csv` chứa thông tin về các phiên duyệt web 2 trang với các trường như câu chuyện, tên miền, loại tin tức và URL.\n",
    "   FORMAT: `STORY \t HOSTNAME \t CATEGORY \t URL`\n",
    "\n",
    "   +, CATEGORY: (b = business, t = science and technology, e = entertainment, m = health)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Đọc dữ liệu từ file CSV\n",
    "data = pd.read_csv('newsCorpora.csv', sep='\\t', header=None, names=['ID', 'TITLE', 'URL', 'PUBLISHER', 'CATEGORY', 'STORY', 'HOSTNAME', 'TIMESTAMP'])\n",
    "\n",
    "# Trích xuất các bài báo từ các nhà xuất bản cụ thể\n",
    "publishers = [\"Reuters\", \"Huffington Post\", \"Businessweek\", \"Contactmusic.com\", \"Daily Mail\"]\n",
    "extracted_examples = data[data['PUBLISHER'].isin(publishers)][['CATEGORY', 'TITLE']] \n",
    "# `extracted_examples` sẽ chứa một DataFrame với các cột `CATEGORY` và `TITLE`, chỉ bao gồm các bài báo từ các nhà xuất bản \"Reuters\", \"Huffington Post\", \"Businessweek\", \"Contactmusic.com\", và \"Daily Mail\".\n",
    "\n",
    "# Sắp xếp lại các example theo thứ tự ngẫu nhiên\n",
    "extracted_examples = extracted_examples.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Phân chia dữ liệu\n",
    "train_size = int(0.8 * len(extracted_examples))\n",
    "valid_size = int(0.1 * len(extracted_examples))\n",
    "\n",
    "train_data = extracted_examples[:train_size]\n",
    "valid_data = extracted_examples[train_size:train_size + valid_size]\n",
    "test_data = extracted_examples[train_size + valid_size:]\n",
    "\n",
    "# Lưu vào các file\n",
    "train_data.to_csv('train.txt', sep='\\t', header=False, index=False)\n",
    "valid_data.to_csv('valid.txt', sep='\\t', header=False, index=False)\n",
    "test_data.to_csv('test.txt', sep='\\t', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "   ```python\n",
    "   extracted_examples = data[data['PUBLISHER'].isin(publishers)][['CATEGORY', 'TITLE']]\n",
    "   ```\n",
    "   - `data['PUBLISHER'].isin(publishers)`: Phần này kiểm tra từng giá trị trong cột `PUBLISHER` của DataFrame `data` để xem nó có nằm trong danh sách `publishers` hay không. Kết quả là một Series boolean (True/False) cho biết mỗi hàng có thuộc về một trong các nhà xuất bản trong danh sách hay không.\n",
    "   - `data[...]`: Sử dụng Series boolean này để lọc DataFrame `data`, chỉ giữ lại các hàng mà nhà xuất bản nằm trong danh sách `publishers`.\n",
    "   - `[['CATEGORY', 'TITLE']]`: Sau khi lọc, chỉ giữ lại hai cột `CATEGORY` và `TITLE` từ DataFrame đã lọc. Kết quả cuối cùng là một DataFrame mới `extracted_examples` chỉ chứa các bài báo từ các nhà xuất bản đã chỉ định, với thông tin về danh mục và tiêu đề của bài báo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2) Khám phá dữ liệu\n",
    " Thực hiện các công việc sau:\n",
    " ● Thốngkêsốsamples cho từng label trong dữ liệu trong tập train, valid và test\n",
    " ● Tính số lượng word trung bình, số lượng word lớn nhất, nhỏ nhất trong các samples\n",
    " trong tập train, valid, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số lượng samples trong tập train:\n",
      "CATEGORY\n",
      "b    4502\n",
      "e    4229\n",
      "t    1213\n",
      "m     728\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Số lượng samples trong tập valid:\n",
      "CATEGORY\n",
      "b    554\n",
      "e    534\n",
      "t    154\n",
      "m     92\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Số lượng samples trong tập test:\n",
      "CATEGORY\n",
      "b    571\n",
      "e    516\n",
      "t    157\n",
      "m     90\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Thống kê số lượng từ trong tập train:\n",
      "Số lượng từ trung bình: 10.468047226386807\n",
      "Số lượng từ lớn nhất: 201\n",
      "Số lượng từ nhỏ nhất: 2\n",
      "\n",
      "Thống kê số lượng từ trong tập valid:\n",
      "Số lượng từ trung bình: 10.41904047976012\n",
      "Số lượng từ lớn nhất: 19\n",
      "Số lượng từ nhỏ nhất: 2\n",
      "\n",
      "Thống kê số lượng từ trong tập test:\n",
      "Số lượng từ trung bình: 10.515742128935532\n",
      "Số lượng từ lớn nhất: 17\n",
      "Số lượng từ nhỏ nhất: 2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Đọc dữ liệu từ các file\n",
    "train_data = pd.read_csv('train.txt', sep='\\t', header=None, names=['CATEGORY', 'TITLE'])\n",
    "valid_data = pd.read_csv('valid.txt', sep='\\t', header=None, names=['CATEGORY', 'TITLE'])\n",
    "test_data = pd.read_csv('test.txt', sep='\\t', header=None, names=['CATEGORY', 'TITLE'])\n",
    "\n",
    "# Bước 2: Thống kê số samples cho từng label\n",
    "train_counts = train_data['CATEGORY'].value_counts()\n",
    "valid_counts = valid_data['CATEGORY'].value_counts()\n",
    "test_counts = test_data['CATEGORY'].value_counts()\n",
    "\n",
    "print(\"Số lượng samples trong tập train:\")\n",
    "print(train_counts)\n",
    "print(\"\\nSố lượng samples trong tập valid:\")\n",
    "print(valid_counts)\n",
    "print(\"\\nSố lượng samples trong tập test:\")\n",
    "print(test_counts)\n",
    "\n",
    "# Bước 3: Tính số lượng từ trung bình, lớn nhất, nhỏ nhất\n",
    "def word_statistics(data):\n",
    "    # Tính số lượng từ trong mỗi tiêu đề\n",
    "    word_counts = data['TITLE'].apply(lambda x: len(x.split()))\n",
    "    return {\n",
    "        'mean': word_counts.mean(),\n",
    "        'max': word_counts.max(),\n",
    "        'min': word_counts.min()\n",
    "    }\n",
    "\n",
    "train_stats = word_statistics(train_data)\n",
    "valid_stats = word_statistics(valid_data)\n",
    "test_stats = word_statistics(test_data)\n",
    "\n",
    "print(\"\\nThống kê số lượng từ trong tập train:\")\n",
    "print(f\"Số lượng từ trung bình: {train_stats['mean']}\")\n",
    "print(f\"Số lượng từ lớn nhất: {train_stats['max']}\")\n",
    "print(f\"Số lượng từ nhỏ nhất: {train_stats['min']}\")\n",
    "\n",
    "print(\"\\nThống kê số lượng từ trong tập valid:\")\n",
    "print(f\"Số lượng từ trung bình: {valid_stats['mean']}\")\n",
    "print(f\"Số lượng từ lớn nhất: {valid_stats['max']}\")\n",
    "print(f\"Số lượng từ nhỏ nhất: {valid_stats['min']}\")\n",
    "\n",
    "print(\"\\nThống kê số lượng từ trong tập test:\")\n",
    "print(f\"Số lượng từ trung bình: {test_stats['mean']}\")\n",
    "print(f\"Số lượng từ lớn nhất: {test_stats['max']}\")\n",
    "print(f\"Số lượng từ nhỏ nhất: {test_stats['min']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-3) Huấn luyện mô hình phân loại\n",
    " Hãy huấn luyện mô hình phân loại văn bản trên dữ liệu train\n",
    " ● Cóthểsửdụngbất kỳ thuật toán phân loại văn bản nào mà bạn biết\n",
    " ● Trong quá trình xây dựng mô hình phân loại văn bản, hãy sử dụng tập valid để lựa\n",
    " chọn siêu tham số (hyper-parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 phương pháp lựa chọn siêu tham số: \n",
    "\n",
    "1. Grid Search:\n",
    "   - Tìm kiếm có hệ thống qua tất cả các kết hợp tham số được xác định trước.\n",
    "   - Đảm bảo tìm ra kết hợp tham số tốt nhất trong không gian tìm kiếm đã định.\n",
    "   - Hiệu quả cho không gian tham số nhỏ và rời rạc.\n",
    "   - Có thể rất chậm với nhiều tham số hoặc khoảng giá trị lớn.\n",
    "\n",
    "2. Random Search:\n",
    "   - Chọn ngẫu nhiên các kết hợp tham số từ phân phối xác định trước.\n",
    "   - Có thể khám phá không gian tham số rộng hơn trong cùng thời gian.\n",
    "   - Hiệu quả hơn cho không gian tham số lớn và liên tục.\n",
    "   - Có thể bỏ qua kết hợp tham số tối ưu, nhưng thường tìm ra giải pháp gần tối ưu nhanh hơn.\n",
    "\n",
    "=> Grid Search đảm bảo tìm ra giải pháp tốt nhất trong không gian tìm kiếm đã định, trong khi Random Search cho phép khám phá không gian rộng hơn và thường nhanh hơn, đặc biệt với nhiều tham số."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Siêu tham số tốt nhất: {'C': 1, 'gamma': 'scale'}\n",
      "\n",
      "Báo cáo phân loại:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           b       0.93      0.95      0.94       554\n",
      "           e       0.92      0.98      0.95       534\n",
      "           m       0.88      0.66      0.76        92\n",
      "           t       0.85      0.73      0.78       154\n",
      "\n",
      "    accuracy                           0.92      1334\n",
      "   macro avg       0.90      0.83      0.86      1334\n",
      "weighted avg       0.91      0.92      0.91      1334\n",
      "\n",
      "Độ chính xác trên tập valid: 0.92\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Bước 1: Đọc dữ liệu từ các file\n",
    "train_data = pd.read_csv('train.txt', sep='\\t', header=None, names=['CATEGORY', 'TITLE'])\n",
    "valid_data = pd.read_csv('valid.txt', sep='\\t', header=None, names=['CATEGORY', 'TITLE'])\n",
    "\n",
    "# Bước 2: Tiền xử lý dữ liệu\n",
    "vectorizer = TfidfVectorizer(max_features=5000)  # Giới hạn số lượng đặc trưng để giảm thời gian tính toán\n",
    "X_train = vectorizer.fit_transform(train_data['TITLE'])\n",
    "y_train = train_data['CATEGORY']\n",
    "X_valid = vectorizer.transform(valid_data['TITLE'])\n",
    "y_valid = valid_data['CATEGORY']\n",
    "\n",
    "# Bước 3: Huấn luyện mô hình SVM\n",
    "svm_model = SVC(kernel='linear', probability=True)\n",
    "\n",
    "# Bước 4: Tối ưu hóa siêu tham số\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "grid_search = GridSearchCV(svm_model, param_grid, cv=5, n_jobs=-1, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# In ra siêu tham số tốt nhất\n",
    "print(\"Siêu tham số tốt nhất:\", grid_search.best_params_)\n",
    "\n",
    "# Sử dụng mô hình với siêu tham số tốt nhất\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Bước 5: Đánh giá mô hình trên tập valid\n",
    "y_pred = best_model.predict(X_valid)\n",
    "\n",
    "# In ra báo cáo phân loại\n",
    "print(\"\\nBáo cáo phân loại:\")\n",
    "print(classification_report(y_valid, y_pred))\n",
    "\n",
    "# In ra độ chính xác\n",
    "accuracy = accuracy_score(y_valid, y_pred)\n",
    "print(f\"Độ chính xác trên tập valid: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-4) Đánh giá mô hình phân loại\n",
    " Đánh giá mô hình phân loại mà bạn đã xây dựng ở bài 2-3) trên tập dữ liệu test. Tính các\n",
    " chỉ số precision, recall, F1 cho từng nhãn và các chỉ số trung bình (macro-average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Báo cáo phân loại chi tiết:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           b       0.91      0.95      0.93       571\n",
      "           e       0.91      0.97      0.94       516\n",
      "           m       0.94      0.68      0.79        90\n",
      "           t       0.85      0.65      0.74       157\n",
      "\n",
      "    accuracy                           0.91      1334\n",
      "   macro avg       0.90      0.81      0.85      1334\n",
      "weighted avg       0.91      0.91      0.90      1334\n",
      "\n",
      "\n",
      "Kết quả trung bình (macro-average):\n",
      "Macro Precision: 0.9027\n",
      "Macro Recall: 0.8137\n",
      "Macro F1-score: 0.8492\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, precision_recall_fscore_support\n",
    "\n",
    "# Đọc dữ liệu test\n",
    "test_data = pd.read_csv('test.txt', sep='\\t', header=None, names=['CATEGORY', 'TITLE'])\n",
    "\n",
    "# Tiền xử lý dữ liệu test\n",
    "X_test = vectorizer.transform(test_data['TITLE'])\n",
    "y_test = test_data['CATEGORY']\n",
    "\n",
    "# Dự đoán nhãn cho tập test\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# In báo cáo phân loại\n",
    "print(\"Báo cáo phân loại chi tiết:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Tính precision, recall, F1 cho từng nhãn và macro-average\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average=None)\n",
    "macro_precision, macro_recall, macro_f1, _ = precision_recall_fscore_support(y_test, y_pred, average='macro')\n",
    "\n",
    "# In kết quả macro-average\n",
    "print(\"\\nKết quả trung bình (macro-average):\")\n",
    "print(f\"Macro Precision: {macro_precision:.4f}\")\n",
    "print(f\"Macro Recall: {macro_recall:.4f}\")\n",
    "print(f\"Macro F1-score: {macro_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  2-5) Triển khai mô hình phân loại thành API\n",
    " Hãy triển khai mô hình phân loại văn bản mà bạn đã xây dựng thành API theo đặc tả sau\n",
    " đây. Có các end-point như mô tả dưới đây.\n",
    " Base URL: http://localhost:2005\n",
    " 2-5-1. Liệt kê danh sách các nhãn\n",
    " API này sẽ liệt kê danh sách các nhãn (labels) trong tập nhãn.\n",
    "- End-point:\n",
    "```\n",
    "/list_label\n",
    " Method: GET\n",
    "```\n",
    "- Request body\n",
    "- Request parameters: NONE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lưu mô hình và vectorizer sau khi huấn luyện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vectorizer.joblib']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib  # Nhập thư viện joblib để lưu và tải mô hình\n",
    "\n",
    "# Lưu mô hình sau khi huấn luyện mô hình\n",
    "joblib.dump(best_model, 'best_model.joblib')  # Lưu mô hình đã huấn luyện vào file 'best_model.joblib'\n",
    "joblib.dump(vectorizer, 'vectorizer.joblib')  # Lưu vectorizer đã sử dụng để chuyển đổi văn bản vào file 'vectorizer.joblib'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://localhost:2005\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [08/Oct/2024 20:56:23] \"GET /list_label HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Oct/2024 20:56:24] \"GET /list_label HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, jsonify\n",
    "import joblib\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Load mô hình và vectorizer đã được huấn luyện\n",
    "model = joblib.load('best_model.joblib')\n",
    "vectorizer = joblib.load('vectorizer.joblib')\n",
    "\n",
    "# Danh sách các nhãn\n",
    "labels = ['b', 'e', 'm', 't']\n",
    "    \n",
    "@app.route('/list_label', methods=['GET'])  # Định nghĩa route cho endpoint '/list_label' với phương thức GET\n",
    "def list_label():\n",
    "    return jsonify({\"labels\": labels})  # Trả về danh sách nhãn dưới dạng JSON\n",
    "\n",
    "from flask import cli  # Nhập cli từ Flask\n",
    "cli.show_server_banner = lambda *_: None  # Tắt banner hiển thị khi chạy server\n",
    "\n",
    "if __name__ == '__main__':  # Kiểm tra xem file có phải là file chính được chạy không\n",
    "    app.run(host='localhost', port=2005, debug=True, use_reloader=False)  # Chạy ứng dụng Flask trên localhost với port 2005"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![images\\API_GET_list_label.png](./images/API_GET_list_label.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 2-5-2. Phân loại văn bản\n",
    "\n",
    "API này nhận đầu vào là một đoạn text và trả ra label của nhãn đó cùng với xác suất (confidence score) tương ứng.\n",
    "\n",
    "#### Endpoint\n",
    "```\n",
    "/classify\n",
    "```\n",
    "\n",
    "#### Method\n",
    "```\n",
    "POST\n",
    "```\n",
    "\n",
    "#### Parameters\n",
    "\n",
    "| Name | Type   | Description          |\n",
    "|------|--------|----------------------|\n",
    "| text | string | Nội dung text đầu vào |\n",
    "\n",
    "#### Response\n",
    "\n",
    "| JSON Key         | Type   | Description                     |\n",
    "|------------------|--------|---------------------------------|\n",
    "| text             | string | Nội dung input text            |\n",
    "| predicted_label  | string | Nhãn dự đoán                   |\n",
    "| prob             | float  | Xác suất của nhãn dự đoán      |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://localhost:2005\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [08/Oct/2024 20:57:23] \"POST /classify HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Oct/2024 20:57:28] \"POST /classify HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Tải mô hình và vectorizer đã được huấn luyện\n",
    "model = joblib.load('best_model.joblib')  # Tải mô hình phân loại\n",
    "vectorizer = joblib.load('vectorizer.joblib')  # Tải vectorizer đã sử dụng để chuyển đổi văn bản\n",
    "\n",
    "@app.route('/classify', methods=['POST'])  # Định nghĩa route cho endpoint '/classify' với phương thức POST\n",
    "def classify():\n",
    "    # Lấy dữ liệu từ request\n",
    "    data = request.json  # Lấy dữ liệu JSON từ yêu cầu\n",
    "    text = data.get('text', '')  # Lấy nội dung văn bản từ dữ liệu, mặc định là chuỗi rỗng\n",
    "\n",
    "    if not text:  \n",
    "        return jsonify({\"error\": \"No text provided\"}), 400  # Trả về lỗi 400 nếu không có văn bản\n",
    "\n",
    "    # Chuyển đổi văn bản thành vector\n",
    "    text_vector = vectorizer.transform([text])  # Chuyển đổi văn bản thành vector sử dụng vectorizer\n",
    "\n",
    "    # Dự đoán nhãn và xác suất\n",
    "    predicted_label = model.predict(text_vector)[0]  # Dự đoán nhãn cho vector văn bản\n",
    "    probabilities = model.predict_proba(text_vector)[0]  # Lấy xác suất cho từng nhãn\n",
    "    \n",
    "    # Lấy xác suất cao nhất\n",
    "    max_prob = np.max(probabilities)  # Tìm xác suất cao nhất trong các xác suất dự đoán\n",
    "\n",
    "    # Chuẩn bị response\n",
    "    response = {\n",
    "        \"text\": text,  # Nội dung văn bản đầu vào\n",
    "        \"predicted_label\": predicted_label,  # Nhãn dự đoán\n",
    "        \"prob\": float(max_prob)  # Xác suất của nhãn dự đoán\n",
    "    }\n",
    "\n",
    "    return jsonify(response)  # Trả về phản hồi dưới dạng JSON\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='localhost', port=2005, debug=True, use_reloader=False)  # Chạy ứng dụng Flask trên localhost với port 2005"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEST API: Test API bằng Postman hoặc công cụ khác.\n",
    "1. Gửi dữ liệu dưới dạng JSON trong body của request, không phải query parameters.\n",
    "Ví dụ: `{\"text\": \"Australia men have third best life ex women\"}`\n",
    "- Và đặt header `Content-Type: application/json`.\n",
    "\n",
    "2. Hoặc Import nhanh bằng: \n",
    "```\n",
    "{\n",
    "  \"info\": {\n",
    "    \"name\": \"News Aggregator API\",\n",
    "    \"_postman_id\": \"unique-id-here\",\n",
    "    \"description\": \"API for classifying news articles\",\n",
    "    \"schema\": \"https://schema.getpostman.com/json/collection/v2.1.0/collection.json\"\n",
    "  },\n",
    "  \"item\": [\n",
    "    {\n",
    "      \"name\": \"Classify Text\",\n",
    "      \"request\": {\n",
    "        \"url\": \"http://localhost:2005/classify\",\n",
    "        \"method\": \"POST\",\n",
    "        \"header\": [\n",
    "          {\n",
    "            \"key\": \"Content-Type\",\n",
    "            \"value\": \"application/json\"\n",
    "          }\n",
    "        ],\n",
    "        \"body\": {\n",
    "          \"mode\": \"raw\",\n",
    "          \"raw\": \"{\\n    \\\"text\\\": \\\"Australia men have third best life expectancy in the world whereas its women\\\"\\n}\"\n",
    "        },\n",
    "        \"description\": \"Classify a given text\"\n",
    "      },\n",
    "      \"response\": []\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![images\\API_GET_classify.png](./images/API_GET_classify.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. So sánh 4 phương thức trong API\n",
    "\n",
    "Trong API, có bốn phương thức HTTP phổ biến mà bạn có thể sử dụng để thực hiện các thao tác khác nhau. Dưới đây là so sánh giữa chúng:\n",
    "\n",
    "| Phương thức | Mô tả | Sử dụng |\n",
    "|-------------|-------|---------|\n",
    "| **GET**     | Lấy dữ liệu từ máy chủ. Không có tác động đến dữ liệu trên máy chủ. | Sử dụng để truy xuất thông tin, ví dụ: lấy danh sách các nhãn. |\n",
    "| **POST**    | Gửi dữ liệu đến máy chủ để tạo mới hoặc cập nhật tài nguyên. | Sử dụng để gửi dữ liệu, ví dụ: phân loại văn bản. |\n",
    "| **PUT**     | Cập nhật toàn bộ tài nguyên trên máy chủ. | Sử dụng để cập nhật một tài nguyên hiện có, ví dụ: cập nhật thông tin của một bài viết. |\n",
    "| **DELETE**  | Xóa tài nguyên trên máy chủ. | Sử dụng để xóa một tài nguyên, ví dụ: xóa một bài viết. |\n",
    "\n",
    "### 2. Các phương pháp phổ biến\n",
    "\n",
    "Dưới đây là một số phương pháp phổ biến trong API:\n",
    "\n",
    "- **REST (Representational State Transfer)**: \n",
    "  - Là một kiến trúc API phổ biến, sử dụng các phương thức HTTP (GET, POST, PUT, DELETE) để thực hiện các thao tác CRUD (Create, Read, Update, Delete).\n",
    "  - Dữ liệu thường được trả về dưới dạng JSON hoặc XML.\n",
    "\n",
    "- **GraphQL**:\n",
    "  - Là một ngôn ngữ truy vấn cho API, cho phép người dùng yêu cầu chính xác dữ liệu mà họ cần.\n",
    "  - Khác với REST, nơi mà mỗi endpoint trả về một loại dữ liệu cụ thể, GraphQL cho phép truy vấn nhiều loại dữ liệu từ một endpoint duy nhất.\n",
    "\n",
    "- **SOAP (Simple Object Access Protocol)**:\n",
    "  - Là một giao thức truyền thông dựa trên XML, thường được sử dụng trong các dịch vụ web.\n",
    "  - SOAP yêu cầu một cấu trúc chặt chẽ và thường sử dụng WSDL (Web Services Description Language) để mô tả dịch vụ.\n",
    "\n",
    "- **gRPC (Google Remote Procedure Call)**:\n",
    "  - Là một framework RPC (Remote Procedure Call) được phát triển bởi Google, sử dụng HTTP/2 và Protocol Buffers.\n",
    "  - gRPC cho phép giao tiếp giữa các dịch vụ với hiệu suất cao và hỗ trợ nhiều ngôn ngữ lập trình.\n",
    "\n",
    "Mỗi phương pháp và kiến trúc API có ưu điểm và nhược điểm riêng, và việc lựa chọn phương pháp nào phụ thuộc vào yêu cầu cụ thể của dự án và môi trường phát triển."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
